## Adaptive Moment Estimation

ADAM combines the ideas of momentum and adaptive learning rates. It computes an adaptive learning rate for each parameter by using estimates of the first and second moments (mean and variance) of the gradients.

## Momentum

Momentum helps accelerate convergence by taking into account the past gradients, reducing oscillations and speeding up the search in the relevant direction.

## RMSprop

RMSprop adjusts the learning rate based on a moving average of the squared gradients, helping with the problem of vanishing or exploding gradients.